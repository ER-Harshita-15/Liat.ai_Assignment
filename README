# Player ReID Assignment - LIAT.AI

This project performs **Player Re-Identification** across two different camera views of a football game using object detection, tracking, and deep visual feature embeddings.

## ğŸ“ Folder Structure

```
Assignment_liat.ai/
â”œâ”€â”€ detect_and_match.py        # Main runner script
â”œâ”€â”€ best.pt                    # Pretrained YOLOv8 model (not in repo due to size)
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ tracker.py             # Player and ball tracking logic
â”‚   â””â”€â”€ matcher.py             # Player matching logic using embeddings
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ matches/               # Debug match images
â”‚   â”œâ”€â”€ broadcast_tracks.pkl   # Pickled detection+tracking results
â”‚   â””â”€â”€ tacticam_tracks.pkl
â”œâ”€â”€ Assignment Materials/
â”‚   â”œâ”€â”€ broadcast.mp4
â”‚   â””â”€â”€ tacticam.mp4
â”œâ”€â”€ player_mappings.csv        # Final ID mapping results
â””â”€â”€ resume.pdf                 # Your latest resume
```

---

## âœ… Assignment Checklist

* [x] Player detection using YOLOv8
* [x] Player tracking using DeepSORT
* [x] Identity matching between views
* [x] Visual+spatial embedding based scoring
* [x] Final mapping CSV created
* [x] Matched image pairs saved for verification
* [x] README with instructions and structure
* [x] Resume attached (`resume.pdf`)
* [ ] Optional: Note on computer vision/VLM experience

---

## âš™ï¸ Setup Instructions

### 1. Create Virtual Environment

```bash
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

If you donâ€™t have a `requirements.txt`, install manually:

```bash
pip install opencv-python torch torchvision ultralytics deep_sort_realtime
```

### 3. Place YOLO Model

Put the provided `best.pt` file (custom YOLOv8 model) into the root folder.

### 4. Run the Main Script

```bash
python detect_and_match.py
```

This will:

* Load or generate tracking data using YOLO and DeepSORT
* Extract deep visual features from frames
* Match players across views using cosine similarity and spatial distance
* Save matched image pairs and ID mappings

---

## ğŸ§  How Matching Works

1. Players are detected and tracked in both videos using YOLO + DeepSORT.
2. Each playerâ€™s best frame is selected based on bounding box area.
3. Cropped images are passed through ResNet18 to extract embeddings.
4. Visual similarity + spatial distance are used to compute a matching score.
5. Debug images are saved, and final mapping is exported to CSV.

---

## ğŸ“„ Output Files

* `player_mappings.csv`: Lists matched player IDs between the two videos
* `results/matches/*.jpg`: Side-by-side comparison images of matched players
* `.pkl` files: Cached detection/tracking outputs to avoid recomputation

---

## ğŸ” Notes

* The object detector is trained specifically on football player and ball classes
* Only valid bounding boxes are used for embeddings
* All preprocessing (resizing, normalization) follows ImageNet standards

---

## ğŸ§© To Improve

* Add OCR to detect jersey numbers
* Use temporal consistency (track overlap) for more robust matching
* Apply L2-normalization to embeddings
* Save matching scores per pair for analysis

---

## ğŸ™Œ Author

Prepared by Harshita Pandey for LIAT.AI assignment.


